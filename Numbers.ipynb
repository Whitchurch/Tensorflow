{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMJM0eQu9sGIhHJwoSg4+gR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Whitchurch/Tensorflow/blob/main/Numbers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0J3NWvNJ2gZ",
        "outputId": "0f7d4a69-3e0e-4de1-a12a-6fdd63c1a46b"
      },
      "source": [
        "!pip install tensorflow-GPU"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed tensorflow-GPU-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRnF4x5oJ6S0"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHLSJbLfKjNL"
      },
      "source": [
        "Point to the MNST numbers database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG2cv2wWKl60"
      },
      "source": [
        "mnist = keras.datasets.mnist"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pugFy8wuKugL"
      },
      "source": [
        "Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NEv0EBLKwIM"
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7auijDhTK4pd"
      },
      "source": [
        "View the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "KPG9E1BNK6AT",
        "outputId": "40ef7ef8-0721-46af-97a9-1c521c9b081e"
      },
      "source": [
        "np.set_printoptions(linewidth=500)\n",
        "picIndex = tf.Variable(3)\n",
        "plt.imshow(training_images[picIndex])\n",
        "print(training_labels[picIndex])\n",
        "print(training_images[picIndex])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "[[0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.48627451 0.99215686 1.         0.24705882 0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.37647059 0.95686275 0.98431373 0.99215686 0.24313725 0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.49803922 0.98431373 0.98431373 0.99215686 0.24313725 0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.26666667 0.9254902  0.98431373 0.82745098 0.12156863 0.03137255 0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.23529412 0.89411765 0.98431373 0.98431373 0.36862745 0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.60784314 0.99215686 0.99215686 0.74117647 0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.07843137 0.99215686 0.98431373 0.92156863 0.25882353 0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.1254902  0.80392157 0.99215686 0.98431373 0.49411765 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.40784314 0.98431373 0.99215686 0.72156863 0.05882353 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.31372549 0.94117647 0.98431373 0.75686275 0.09019608 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.1254902  0.99215686 0.99215686 0.99215686 0.62352941 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.59215686 0.98431373 0.98431373 0.98431373 0.15294118 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.18823529 0.86666667 0.98431373 0.98431373 0.6745098  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.91764706 0.98431373 0.98431373 0.76862745 0.04705882 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.99215686 0.98431373 0.98431373 0.34901961 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.62352941 1.         0.99215686 0.99215686 0.12156863 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.18823529 0.89411765 0.99215686 0.96862745 0.54901961 0.03137255 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.25098039 0.98431373 0.99215686 0.8627451  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.25098039 0.98431373 0.99215686 0.8627451  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.09411765 0.75686275 0.99215686 0.8627451  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyIRMzinLhdg"
      },
      "source": [
        "Normalize the data, so that the certain feature weights don't dominate the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRgMZlZyLtIP"
      },
      "source": [
        "training_images = training_images/255\n",
        "test_images = test_images/255"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cO77N4RFL89g"
      },
      "source": [
        "View the normalized data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctBMKpOsL-gZ"
      },
      "source": [
        "plt.imshow(training_images[picIndex])\n",
        "print(training_images[picIndex])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dLDAK9oMuAR"
      },
      "source": [
        "Now let us design the model: It has 128 neurons and 10 output softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0XR9ISeMvnI",
        "outputId": "df95d034-b39b-40c2-f167-7cb3558c59ba"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy') >= 0.99): # Experiment with changing this value\n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "\n",
        "mycallbacks = myCallback()\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),  \n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=10, callbacks=[mycallbacks])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2607 - accuracy: 0.9262\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1150 - accuracy: 0.9655\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0786 - accuracy: 0.9758\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0587 - accuracy: 0.9818\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0464 - accuracy: 0.9857\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0364 - accuracy: 0.9887\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0282 - accuracy: 0.9914\n",
            "\n",
            "Reached 99% accuracy so cancelling training!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0e63458cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxXTtfKHOQOm"
      },
      "source": [
        "Send in training data into the model to see how it behaves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q62z4ipPQ3wX",
        "outputId": "79479950-512c-49d3-cec6-1d2c289f9bdf"
      },
      "source": [
        "model.evaluate(test_images,test_labels)\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9773\n",
            "[2.7598032e-10 1.3343663e-12 6.9377711e-07 1.3404792e-07 1.5241084e-13 4.6593202e-10 3.1026082e-15 9.9999905e-01 7.8634848e-08 9.1448150e-08]\n",
            "7\n"
          ]
        }
      ]
    }
  ]
}