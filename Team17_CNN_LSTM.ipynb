{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Team17_CNN_LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMh9zClJQMQv3e6WTNX5+YO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Whitchurch/Tensorflow/blob/main/Team17_CNN_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJCjQ8fSb-M1"
      },
      "source": [
        "!pip install tensorflow-GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NI8e-OL5rtyG",
        "outputId": "e8f6b833-5825-42bc-f61a-35ef88d5a333"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxKbf6z3cT3G"
      },
      "source": [
        "Install Tensorflow on Google Co-lab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zNXb0FNcr7S"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import csv \n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import CuDNNLSTM # A superior LSTM that uses GPU more optimized for training.\n",
        "from keras.layers import LSTM\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YCMbF1LslRM"
      },
      "source": [
        "Steps to pre-process and load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q76uho-Lsp47"
      },
      "source": [
        "os.chdir(\"drive/My Drive/Colab Notebooks\")\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPKqnFBNszh3",
        "outputId": "ff140494-7c87-4abe-e1a8-f534be8d993f"
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Access_Local_directory.ipynb\n",
            "'Copy of Untitled0.ipynb'\n",
            " ECGsignal.csv\n",
            " ECGsignal_n.csv\n",
            " ECGsignal_nwhite.csv\n",
            " Exercise_1_Cats_vs_Dogs_Question-FINAL.ipynb\n",
            " Exercise_2_Cats_vs_Dogs_using_augmentation_Question-FINAL.ipynb\n",
            " Exercise_3_Horses_vs_humans_using_Transfer_Learning_Question-FINAL.ipynb\n",
            " Exercise_4_Multi_class_classifier_Question-FINAL.ipynb\n",
            " FinalCNN_Beginner.ipynb\n",
            " Team17_CNN_LSTM.ipynb\n",
            " Untitled0.ipynb\n",
            " Untitled1.ipynb\n",
            " Untitled2.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_WYmzcttPiG",
        "outputId": "2db40338-c8ff-4b3c-8d59-4830c9da3809"
      },
      "source": [
        "#Read the clean signal\n",
        "with open('ECGsignal.csv') as csv_file:\n",
        "  csv_reader = csv.reader(csv_file)\n",
        "\n",
        "  for ECGsignal in csv_reader:\n",
        "    print(ECGsignal)\n",
        "  print(\"Finished reading the file\")\n",
        "\n",
        "#Time to dissect the file read data's anatomy:\n",
        "#Total number of items in the list:\n",
        "len(ECGsignal)\n",
        "\n",
        "#Convert the list to an array \n",
        "ECGsignal_arr = np.array(ECGsignal,dtype=float)\n",
        "\n",
        "#Read the noisy signal\n",
        "with open('ECGsignal_n.csv') as csv_file:\n",
        "  csv_reader = csv.reader(csv_file)\n",
        "\n",
        "  for ECGsignal_n in csv_reader:\n",
        "    print(ECGsignal_n)\n",
        "  print(\"Finished reading the file\")\n",
        "\n",
        "#Time to dissect the file read data's anatomy:\n",
        "#Total number of items in the list:\n",
        "len(ECGsignal_n)\n",
        "\n",
        "#Convert the list to an array \n",
        "ECGsignal_n_arr = np.array(ECGsignal_n,dtype=float)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2YBfWXfv5Ke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52961dfe-f385-42de-9c68-7f9b1527ad6d"
      },
      "source": [
        "tupleofdimensions = ECGsignal_arr.shape\n",
        "num = tupleofdimensions[0]\n",
        "Training_test_Split = 0.95  # Modify this line to control the Test-Train split\n",
        "\n",
        "a=Training_test_Split*num;                                 \n",
        "XTrain=ECGsignal_n_arr[0:int(a)];                  \n",
        "YTrain=ECGsignal_arr[0:int(a)];\n",
        "XTest=ECGsignal_n_arr[int(a):num];               \n",
        "YTest=ECGsignal_arr[int(a):num];\n",
        "\n",
        "train_samples=30*60*Training_test_Split/10;\n",
        "test_samples =30*60*(1-Training_test_Split)/10;\n",
        "\n",
        "print(int(train_samples))\n",
        "print(int(test_samples))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "171\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94xeGV8y1Gyg"
      },
      "source": [
        "Break up the Train and Test data into 4D vectors for the Tensorflow CNN: Format is [Batch_size,Height,width,depth]\n",
        "\n",
        "Reference:https://towardsdatascience.com/understanding-input-and-output-shapes-in-convolution-network-keras-f143923d56ca"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQwVYV0r1UYy"
      },
      "source": [
        "XTrain_reshaped = np.reshape(XTrain,(int(train_samples),30000,1,1))\n",
        "YTrain_reshaped = np.reshape(YTrain,(int(train_samples),30000))\n",
        "\n",
        "XTest_reshaped = np.reshape(XTest,(int(test_samples),30000,1,1))\n",
        "YTest_reshaped = np.reshape(YTest,(int(test_samples),30000))\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DS4G6DNdkC3"
      },
      "source": [
        "Start defining the layers of the CNN - From the De-noising paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppaaL62fdjsJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46efdad0-2339-4500-cd36-9a3ecf3d748a"
      },
      "source": [
        "model = Sequential(name=\"DNN_using_CNN_for_Denoising\")\n",
        "\n",
        "# Convolution layers are used to extract the most prominent features of the input data.\n",
        "#Layer 1:\n",
        "#Conv-layer -> BatchNorm -> RELU-> AvdPooling\n",
        "model.add(Conv2D(36, (19,1), input_shape=(30000,1,1),activation='relu',padding='SAME',strides=(1,1),name='conv_1')) \n",
        "model.add(BatchNormalization(name='batchnorm_1'))\n",
        "model.add(Dense(units=36,activation='relu',name='relu_1'))\n",
        "model.add(AveragePooling2D(pool_size=(2,1),strides=(4,1),name='avgpool_1'))\n",
        "\n",
        "#Layer 2:\n",
        "#Conv-layer -> BatchNorm -> RELU-> AvdPooling\n",
        "model.add(Conv2D(36,(19,1),strides=(1,1),padding='SAME',name='conv_2'))\n",
        "model.add(BatchNormalization(name='batchnorm_2'))\n",
        "model.add(Dense(units=36,activation='relu',name='relu_2'))\n",
        "model.add(AveragePooling2D(pool_size=(2,1),strides=(4,1),name='avgpool_2'))\n",
        "\n",
        "#Layer 3:\n",
        "#Conv-layer -> BatchNorm -> RELU-> AvdPooling\n",
        "model.add(Conv2D(36,(19,1),strides=(1,1),padding='SAME',name='conv_3'))\n",
        "model.add(BatchNormalization(name='batchnorm_3'))\n",
        "model.add(Dense(units=36,activation='relu',name='relu_3'))\n",
        "model.add(AveragePooling2D(pool_size=(2,1),strides=(4,1),name='avgpool_3'))\n",
        "\n",
        "#Layer 4:\n",
        "#Conv-layer -> BatchNorm -> RELU-> AvdPooling\n",
        "model.add(Conv2D(36,(19,1),strides=(1,1),padding='SAME',name='conv_4'))\n",
        "model.add(BatchNormalization(name='batchnorm_4'))\n",
        "model.add(Dense(units=36,activation='relu',name='relu_4'))\n",
        "model.add(AveragePooling2D(pool_size=(2,1),strides=(4,1),name='avgpool_4'))\n",
        "\n",
        "\n",
        "#Layer 5:\n",
        "#Conv-layer -> BatchNorm -> RELU-> AvdPooling\n",
        "model.add(Conv2D(36,(19,1),strides=(1,1),padding='SAME',name='conv_5'))\n",
        "model.add(BatchNormalization(name='batchnorm_5'))\n",
        "model.add(Dense(units=36,activation='relu',name='relu_5'))\n",
        "model.add(AveragePooling2D(pool_size=(2,1),strides=(4,1),name='avgpool_5'))\n",
        "\n",
        "\n",
        "#Layer 6:\n",
        "#Conv-layer -> BatchNorm -> RELU-> AvdPooling\n",
        "model.add(Conv2D(36,(19,1),strides=(1,1),padding='SAME',name='conv_6'))\n",
        "model.add(BatchNormalization(name='batchnorm_6'))\n",
        "model.add(Dense(units=36,activation='relu',name='relu_6'))\n",
        "model.add(AveragePooling2D(pool_size=(2,1),strides=(4,1),name='avgpool_6'))\n",
        "model.add(Flatten())\n",
        "\n",
        "#Now adding in the fully-connected dense layer: This will act on the data extracted from the CNN in the prior stages\n",
        "model.add(Dense(units= 30000,activation=None,use_bias=True))\n",
        "model.summary()\n",
        "\n",
        "#Last layer of the FCN is only showing the inputsx weight.  \n",
        "#Investigating to see, if the bias is used. even though model summary is not displaying it.\n",
        "#weights, biases = model.layers[25].get_weights()\n",
        "#print(len(weights))\n",
        "#print(len(biases))\n",
        "\n",
        "#Build the model, we follow the paper, using Adam optimizer, for speeding up gradient descent\n",
        "#And RMS as the cost function, metric to optimize against.\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['mse'])\n",
        "\n",
        "#Fit the model.\n",
        "# Train the Model\n",
        "#history = model.fit_generator(train_generator,validation_data = validation_generator, epochs = 10,steps_per_epoch = 1372, validation_steps = 350,verbose = 1 )\n",
        "history = model.fit(XTrain_reshaped,YTrain_reshaped,epochs=50,verbose=2,validation_data=(XTest_reshaped,YTest_reshaped))\n",
        "\n",
        "# Plot the chart for accuracy and loss on both training and validation\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "mse = history.history['mse']\n",
        "val_mse = history.history['val_mse']\n",
        "\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, mse, 'r', label='MSE')\n",
        "plt.plot(epochs, val_mse, 'b', label='Validation MSE')\n",
        "plt.title('Training and validation MSE')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.show()\n",
        "                                    "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"DNN_using_CNN_for_Denoising\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_1 (Conv2D)              (None, 30000, 1, 36)      720       \n",
            "_________________________________________________________________\n",
            "batchnorm_1 (BatchNormalizat (None, 30000, 1, 36)      144       \n",
            "_________________________________________________________________\n",
            "relu_1 (Dense)               (None, 30000, 1, 36)      1332      \n",
            "_________________________________________________________________\n",
            "avgpool_1 (AveragePooling2D) (None, 7500, 1, 36)       0         \n",
            "_________________________________________________________________\n",
            "conv_2 (Conv2D)              (None, 7500, 1, 36)       24660     \n",
            "_________________________________________________________________\n",
            "batchnorm_2 (BatchNormalizat (None, 7500, 1, 36)       144       \n",
            "_________________________________________________________________\n",
            "relu_2 (Dense)               (None, 7500, 1, 36)       1332      \n",
            "_________________________________________________________________\n",
            "avgpool_2 (AveragePooling2D) (None, 1875, 1, 36)       0         \n",
            "_________________________________________________________________\n",
            "conv_3 (Conv2D)              (None, 1875, 1, 36)       24660     \n",
            "_________________________________________________________________\n",
            "batchnorm_3 (BatchNormalizat (None, 1875, 1, 36)       144       \n",
            "_________________________________________________________________\n",
            "relu_3 (Dense)               (None, 1875, 1, 36)       1332      \n",
            "_________________________________________________________________\n",
            "avgpool_3 (AveragePooling2D) (None, 469, 1, 36)        0         \n",
            "_________________________________________________________________\n",
            "conv_4 (Conv2D)              (None, 469, 1, 36)        24660     \n",
            "_________________________________________________________________\n",
            "batchnorm_4 (BatchNormalizat (None, 469, 1, 36)        144       \n",
            "_________________________________________________________________\n",
            "relu_4 (Dense)               (None, 469, 1, 36)        1332      \n",
            "_________________________________________________________________\n",
            "avgpool_4 (AveragePooling2D) (None, 117, 1, 36)        0         \n",
            "_________________________________________________________________\n",
            "conv_5 (Conv2D)              (None, 117, 1, 36)        24660     \n",
            "_________________________________________________________________\n",
            "batchnorm_5 (BatchNormalizat (None, 117, 1, 36)        144       \n",
            "_________________________________________________________________\n",
            "relu_5 (Dense)               (None, 117, 1, 36)        1332      \n",
            "_________________________________________________________________\n",
            "avgpool_5 (AveragePooling2D) (None, 29, 1, 36)         0         \n",
            "_________________________________________________________________\n",
            "conv_6 (Conv2D)              (None, 29, 1, 36)         24660     \n",
            "_________________________________________________________________\n",
            "batchnorm_6 (BatchNormalizat (None, 29, 1, 36)         144       \n",
            "_________________________________________________________________\n",
            "relu_6 (Dense)               (None, 29, 1, 36)         1332      \n",
            "_________________________________________________________________\n",
            "avgpool_6 (AveragePooling2D) (None, 7, 1, 36)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 252)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 30000)             7590000   \n",
            "=================================================================\n",
            "Total params: 7,722,876\n",
            "Trainable params: 7,722,444\n",
            "Non-trainable params: 432\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "6/6 - 3s - loss: 0.2574 - mse: 0.2574 - val_loss: 0.1817 - val_mse: 0.1817\n",
            "Epoch 2/50\n",
            "6/6 - 1s - loss: 0.1380 - mse: 0.1380 - val_loss: 0.3192 - val_mse: 0.3192\n",
            "Epoch 3/50\n",
            "6/6 - 1s - loss: 0.1288 - mse: 0.1288 - val_loss: 2.4842 - val_mse: 2.4842\n",
            "Epoch 4/50\n",
            "6/6 - 1s - loss: 0.1290 - mse: 0.1290 - val_loss: 4.6232 - val_mse: 4.6232\n",
            "Epoch 5/50\n",
            "6/6 - 1s - loss: 0.1245 - mse: 0.1245 - val_loss: 6.7735 - val_mse: 6.7735\n",
            "Epoch 6/50\n",
            "6/6 - 1s - loss: 0.1254 - mse: 0.1254 - val_loss: 8.3977 - val_mse: 8.3977\n",
            "Epoch 7/50\n",
            "6/6 - 1s - loss: 0.1206 - mse: 0.1206 - val_loss: 7.5580 - val_mse: 7.5580\n",
            "Epoch 8/50\n",
            "6/6 - 1s - loss: 0.1186 - mse: 0.1186 - val_loss: 3.6561 - val_mse: 3.6561\n",
            "Epoch 9/50\n",
            "6/6 - 1s - loss: 0.1177 - mse: 0.1177 - val_loss: 2.3428 - val_mse: 2.3428\n",
            "Epoch 10/50\n",
            "6/6 - 1s - loss: 0.1194 - mse: 0.1194 - val_loss: 1.8774 - val_mse: 1.8774\n",
            "Epoch 11/50\n",
            "6/6 - 1s - loss: 0.1183 - mse: 0.1183 - val_loss: 1.6882 - val_mse: 1.6882\n",
            "Epoch 12/50\n",
            "6/6 - 1s - loss: 0.1172 - mse: 0.1172 - val_loss: 0.7405 - val_mse: 0.7405\n",
            "Epoch 13/50\n",
            "6/6 - 1s - loss: 0.1171 - mse: 0.1171 - val_loss: 0.3202 - val_mse: 0.3202\n",
            "Epoch 14/50\n",
            "6/6 - 1s - loss: 0.1141 - mse: 0.1141 - val_loss: 0.3260 - val_mse: 0.3260\n",
            "Epoch 15/50\n",
            "6/6 - 1s - loss: 0.1149 - mse: 0.1149 - val_loss: 0.3411 - val_mse: 0.3411\n",
            "Epoch 16/50\n",
            "6/6 - 1s - loss: 0.1133 - mse: 0.1133 - val_loss: 0.3248 - val_mse: 0.3248\n",
            "Epoch 17/50\n",
            "6/6 - 1s - loss: 0.1128 - mse: 0.1128 - val_loss: 0.3938 - val_mse: 0.3938\n",
            "Epoch 18/50\n",
            "6/6 - 1s - loss: 0.1133 - mse: 0.1133 - val_loss: 0.3363 - val_mse: 0.3363\n",
            "Epoch 19/50\n",
            "6/6 - 1s - loss: 0.1102 - mse: 0.1102 - val_loss: 0.2037 - val_mse: 0.2037\n",
            "Epoch 20/50\n",
            "6/6 - 1s - loss: 0.1118 - mse: 0.1118 - val_loss: 0.1982 - val_mse: 0.1982\n",
            "Epoch 21/50\n",
            "6/6 - 1s - loss: 0.1103 - mse: 0.1103 - val_loss: 0.1651 - val_mse: 0.1651\n",
            "Epoch 22/50\n",
            "6/6 - 1s - loss: 0.1083 - mse: 0.1083 - val_loss: 0.1703 - val_mse: 0.1703\n",
            "Epoch 23/50\n",
            "6/6 - 1s - loss: 0.1058 - mse: 0.1058 - val_loss: 0.1642 - val_mse: 0.1642\n",
            "Epoch 24/50\n",
            "6/6 - 1s - loss: 0.1038 - mse: 0.1038 - val_loss: 0.1626 - val_mse: 0.1626\n",
            "Epoch 25/50\n",
            "6/6 - 1s - loss: 0.1041 - mse: 0.1041 - val_loss: 0.1713 - val_mse: 0.1713\n",
            "Epoch 26/50\n",
            "6/6 - 1s - loss: 0.1022 - mse: 0.1022 - val_loss: 0.1721 - val_mse: 0.1721\n",
            "Epoch 27/50\n",
            "6/6 - 1s - loss: 0.1030 - mse: 0.1030 - val_loss: 0.1710 - val_mse: 0.1710\n",
            "Epoch 28/50\n",
            "6/6 - 1s - loss: 0.0987 - mse: 0.0987 - val_loss: 0.1711 - val_mse: 0.1711\n",
            "Epoch 29/50\n",
            "6/6 - 1s - loss: 0.0988 - mse: 0.0988 - val_loss: 0.1674 - val_mse: 0.1674\n",
            "Epoch 30/50\n",
            "6/6 - 1s - loss: 0.0989 - mse: 0.0989 - val_loss: 0.1766 - val_mse: 0.1766\n",
            "Epoch 31/50\n",
            "6/6 - 1s - loss: 0.0988 - mse: 0.0988 - val_loss: 0.1921 - val_mse: 0.1921\n",
            "Epoch 32/50\n",
            "6/6 - 1s - loss: 0.0962 - mse: 0.0962 - val_loss: 0.2411 - val_mse: 0.2411\n",
            "Epoch 33/50\n",
            "6/6 - 1s - loss: 0.0901 - mse: 0.0901 - val_loss: 0.2473 - val_mse: 0.2473\n",
            "Epoch 34/50\n",
            "6/6 - 1s - loss: 0.0897 - mse: 0.0897 - val_loss: 0.2179 - val_mse: 0.2179\n",
            "Epoch 35/50\n",
            "6/6 - 1s - loss: 0.0901 - mse: 0.0901 - val_loss: 0.2057 - val_mse: 0.2057\n",
            "Epoch 36/50\n",
            "6/6 - 1s - loss: 0.0893 - mse: 0.0893 - val_loss: 0.2643 - val_mse: 0.2643\n",
            "Epoch 37/50\n",
            "6/6 - 1s - loss: 0.0879 - mse: 0.0879 - val_loss: 0.2352 - val_mse: 0.2352\n",
            "Epoch 38/50\n",
            "6/6 - 1s - loss: 0.0885 - mse: 0.0885 - val_loss: 0.2076 - val_mse: 0.2076\n",
            "Epoch 39/50\n",
            "6/6 - 1s - loss: 0.0850 - mse: 0.0850 - val_loss: 0.2130 - val_mse: 0.2130\n",
            "Epoch 40/50\n",
            "6/6 - 1s - loss: 0.0827 - mse: 0.0827 - val_loss: 0.2113 - val_mse: 0.2113\n",
            "Epoch 41/50\n",
            "6/6 - 1s - loss: 0.0795 - mse: 0.0795 - val_loss: 0.1904 - val_mse: 0.1904\n",
            "Epoch 42/50\n",
            "6/6 - 1s - loss: 0.0876 - mse: 0.0876 - val_loss: 0.1906 - val_mse: 0.1906\n",
            "Epoch 43/50\n",
            "6/6 - 1s - loss: 0.0837 - mse: 0.0837 - val_loss: 0.2518 - val_mse: 0.2518\n",
            "Epoch 44/50\n",
            "6/6 - 1s - loss: 0.0832 - mse: 0.0832 - val_loss: 0.2874 - val_mse: 0.2874\n",
            "Epoch 45/50\n",
            "6/6 - 1s - loss: 0.0824 - mse: 0.0824 - val_loss: 0.2218 - val_mse: 0.2218\n",
            "Epoch 46/50\n",
            "6/6 - 1s - loss: 0.0777 - mse: 0.0777 - val_loss: 0.2012 - val_mse: 0.2012\n",
            "Epoch 47/50\n",
            "6/6 - 1s - loss: 0.0801 - mse: 0.0801 - val_loss: 0.2458 - val_mse: 0.2458\n",
            "Epoch 48/50\n",
            "6/6 - 1s - loss: 0.0810 - mse: 0.0810 - val_loss: 0.2279 - val_mse: 0.2279\n",
            "Epoch 49/50\n",
            "6/6 - 1s - loss: 0.0795 - mse: 0.0795 - val_loss: 0.3267 - val_mse: 0.3267\n",
            "Epoch 50/50\n",
            "6/6 - 1s - loss: 0.0752 - mse: 0.0752 - val_loss: 0.3863 - val_mse: 0.3863\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOt07WKtDirw"
      },
      "source": [
        "Start defining the LSTM implementation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VaLOkLGxoJ1"
      },
      "source": [
        "RE-shape the Data so that it can be used in the LSTM:  \n",
        "LSTM Input = [Sample,TimeSteps,Features]\n",
        "In out case it is: [Test/Training samples, 30000,1]\n",
        "\n",
        "Reference:\n",
        "https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2rC2nZWxr0x",
        "outputId": "61dbd7d2-0ca5-460e-ea07-4f0077287cc0"
      },
      "source": [
        "XTrain_reshaped = XTrain.reshape(int(train_samples),30000,1)\n",
        "YTrain_reshaped = YTrain.reshape(int(train_samples),30000,1)\n",
        "\n",
        "XTest_reshaped = XTest.reshape(int(test_samples),30000,1)\n",
        "YTest_reshaped = YTest.reshape(int(test_samples),30000,1)\n",
        "\n",
        "#print the input data shapes:\n",
        "print(\"Training data shapes: Input and Output\")\n",
        "print(XTrain_reshaped.shape)\n",
        "print(YTrain_reshaped.shape)\n",
        "\n",
        "print(\"Test data shapes: Input and Output\")\n",
        "print(XTest_reshaped.shape)\n",
        "print(YTest_reshaped.shape)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shapes: Input and Output\n",
            "(171, 30000, 1)\n",
            "(171, 30000, 1)\n",
            "Test data shapes: Input and Output\n",
            "(9, 30000, 1)\n",
            "(9, 30000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVs4JvKHxkMo"
      },
      "source": [
        "The definition of the LSTM model follows below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe2pXI_YDnc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55e600b-5c67-4103-f35f-d23a13adb4a5"
      },
      "source": [
        "model1 = Sequential(name=\"DNN_using_LSTM_for_Denoising\");\n",
        "#The LSTM->RELU-> return sequential ouput.\n",
        "#model1.add(CuDNNLSTM(140,input_shape=(30000,1),name=\"lstm_1_relu_1\",return_sequences=True)) \n",
        "model1.add(LSTM(140,input_shape=(30000,1),name=\"lstm_1_relu_1\",activation='relu',return_sequences=True)) \n",
        "# sequential output/input -> LSTM2->Relu -> flattened output (return_sequence = false, by default)\n",
        "#The output of LSTM2 is a flattened output -> Fully connected layer.\n",
        "#model1.add(CuDNNLSTM(140,name=\"lstm_2_relu_2\"))\n",
        "model1.add(LSTM(140,name=\"lstm_2_relu_2\",activation='relu'))\n",
        "#Add the fully connected layer of 30000 \n",
        "model1.add(Dense(30000,activation=None))\n",
        "model1.summary()\n",
        "\n",
        "#Build the model, we follow the paper, using Adam optimizer, for speeding up gradient descent\n",
        "#And RMS as the cost function, metric to optimize against.\n",
        "optimizer = keras.optimizers.Adam(lr=0.01)\n",
        "#Compile the model\n",
        "model1.compile(optimizer=optimizer,loss='mean_squared_error',metrics=['mse','loss'])\n",
        "\n",
        "#Fit the model.\n",
        "# Train the Model\n",
        "history = model1.fit(XTrain_reshaped,YTrain_reshaped,epochs=1,validation_data=(XTest_reshaped,YTest_reshaped),verbose=1)\n",
        "\n",
        "# Plot the chart for accuracy and loss on both training and validation\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['mse']\n",
        "val_acc = history.history['val_mse']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_1_relu_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2_relu_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"DNN_using_LSTM_for_Denoising\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1_relu_1 (LSTM)         (None, 30000, 140)        79520     \n",
            "_________________________________________________________________\n",
            "lstm_2_relu_2 (LSTM)         (None, 140)               157360    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 30000)             4230000   \n",
            "=================================================================\n",
            "Total params: 4,466,880\n",
            "Trainable params: 4,466,880\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmjWCEyTgRgC"
      },
      "source": [
        "Helpful references:\n",
        "\n",
        "1)This explains why last dense layer has no activation function:\n",
        "  - we primarily do that if we are trying to accuractely do regression.\n",
        "\n",
        "https://stats.stackexchange.com/questions/361066/what-is-the-point-of-having-a-dense-layer-in-a-neural-network-with-no-activation\n",
        "\n",
        "2)This video shows how to implement a stacked LSTM model:\n",
        "https://www.youtube.com/watch?v=BSpXCRTOLJA\n",
        "\n",
        "3) This video shows the inner anatomy of an LSTM, primarily the sigmoid and Tanh, used for gating inside the LSTM:\n",
        "https://www.youtube.com/watch?v=8HyCNIVRbSU&t=632s\n",
        "\n",
        "4) The blogpost that references the video in 3. Is linked here:\n",
        "https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
        "\n",
        "5) This is the link from Andrew NG, I studied to understand, why we use BatchNormalization in the CNN:\n",
        "https://www.youtube.com/watch?v=nUUqwaxLnWs\n",
        "\n",
        "6) Running on CPU vs GPU vs TPU???\n",
        "https://serverguy.com/comparison/cpu-vs-gpu-vs-tpu/\n",
        "\n",
        "\n"
      ]
    }
  ]
}